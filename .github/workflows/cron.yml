name: Cron Scrape

on:
  schedule:
    - cron: "*/10 * * * *"  # Set this to your preferred schedule

permissions:
  contents: write

concurrency:
  group: scraper
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    name: Run scrape.mjs and commit changes
    env:
      GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

    steps:
    - uses: actions/checkout@v3

    # Set up Node.js environment
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: 20.3.0

    # Install dependencies including puppeteer and necessary libraries
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget curl
        sudo apt-get install -y libglib2.0-0 libnss3 libx11-xcb1 libxcomposite1 libxrandr2 libgbm1
        npm install

    # Configure git for pushing changes
    - name: Configure git
      run: |
        git config --global user.name "gh-actions"
        git config --global user.email "gh-actions@github.com"
        git remote set-url origin https://git:${GITHUB_TOKEN}@github.com/${{github.repository}}.git

    # Run the Puppeteer scraping script
    - name: Run scrape.mjs
      run: npm run main

    # Commit the scraped data to the repository
    - name: Commit scraped data
      run: |
        git commit --allow-empty -am "update scraped.json"

    # Push the changes to the repository
    - name: Push changes to repository
      run: git push --verbose
