name: Cron Scrape

on:
  schedule:
    - cron: "*/10 * * * *"  # Change to your preferred schedule

permissions:
  contents: write

concurrency:
  group: scraper
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    name: Run scrape.mjs and commit changes
    env:
      GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

    steps:
      # Checkout the code
      - uses: actions/checkout@v3

      # Setup Node.js environment
      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: 20.3.0

      # Install dependencies (including puppeteer)
      - run: npm install puppeteer

       # Handle unstaged changes by committing or stashing
      - name: Commit unstaged changes (if any)
        run: |
          git diff --exit-code || git commit --allow-empty -am "Temporary commit to handle unstaged changes"

      # Pull the latest changes from the remote repository before running the scraping script
      - name: Pull latest changes from main branch
        run: |
          git fetch origin
          git checkout main
          git pull origin main --rebase

      
      # Run your scraping script
      - run: npm run main

      # Configure git for pushing changes
      - run: |
          git config --global user.name "gh-actions"
          git config --global user.email "gh-actions@github.com"
          git remote set-url origin https://git:${GITHUB_TOKEN}@github.com/${{github.repository}}.git
     
      # Commit and push scraped data
      - run: |
          git commit --allow-empty -am "update scraped.json"
          git push
